{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from torchsummary import summary\n",
    "import shutil\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple MNIST model, with only 6 layers. Global Average Pooling (GAP) and dense layers are used at last for consistent weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "            Conv2d-3           [-1, 16, 28, 28]           2,320\n",
      "              ReLU-4           [-1, 16, 28, 28]               0\n",
      "            Conv2d-5           [-1, 32, 14, 14]           4,640\n",
      "              ReLU-6           [-1, 32, 14, 14]               0\n",
      "            Conv2d-7           [-1, 32, 14, 14]           9,248\n",
      "              ReLU-8           [-1, 32, 14, 14]               0\n",
      "            Conv2d-9             [-1, 64, 7, 7]          18,496\n",
      "             ReLU-10             [-1, 64, 7, 7]               0\n",
      "           Conv2d-11             [-1, 64, 7, 7]          36,928\n",
      "             ReLU-12             [-1, 64, 7, 7]               0\n",
      "AdaptiveAvgPool2d-13             [-1, 64, 1, 1]               0\n",
      "           Linear-14                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 72,442\n",
      "Trainable params: 72,442\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.67\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 0.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "log_batch = 10\n",
    "unit_num = 16\n",
    "\n",
    "def _make_layer(in_shape, out_shape, unit_num):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_shape, unit_num, 3, 1, 1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(unit_num, out_shape, 3, 1, 1),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.conv11 = nn.Conv2d(1, unit_num, 3, 1, 1)\n",
    "        #self.conv12 = nn.Conv2d(unit_num, unit_num, 3, 1, 1)\n",
    "        #self.conv21 = nn.Conv2d(unit_num, unit_num*2, 3, 1, 1)\n",
    "        #self.conv22 = nn.Conv2d(unit_num*2, unit_num*2, 3, 1, 1)\n",
    "        #self.conv31 = nn.Conv2d(unit_num*2, unit_num*4, 3, 1, 1)\n",
    "        #self.conv32 = nn.Conv2d(unit_num*4, unit_num*4, 3, 1, 1)\n",
    "        self.layer1 = _make_layer(1,unit_num,unit_num)\n",
    "        self.layer2 = _make_layer(unit_num,unit_num*2,unit_num*2)\n",
    "        self.layer3 = _make_layer(unit_num*2,unit_num*4,unit_num*4)\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(unit_num*4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = self.gap(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        #output = F.softmax(x, dim=1)\n",
    "        #x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "model = Net()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset are stored in '/dataset'. If you want to change this, remember to change the root for ClassesLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "data_train = datasets.MNIST(root = \"/dataset\",\n",
    "                            transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = datasets.MNIST(root=\"/dataset\",\n",
    "                           transform = transform,\n",
    "                           train = False)\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True,\n",
    "                                                 num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True,\n",
    "                                                num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want a perfect MNIST classifier. Around 97% accuracy is enough for the explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/15\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\envs\\DL2\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:1.83608679, Train Accuracy is:62.21%, Test Accuracy is:76.64%\n",
      "Epoch 1/15\n",
      "----------\n",
      "Loss is:1.60629953, Train Accuracy is:85.51%, Test Accuracy is:86.97%\n",
      "Epoch 2/15\n",
      "----------\n",
      "Loss is:1.58694479, Train Accuracy is:87.35%, Test Accuracy is:88.19%\n",
      "Epoch 3/15\n",
      "----------\n",
      "Loss is:1.58083358, Train Accuracy is:87.95%, Test Accuracy is:88.69%\n",
      "Epoch 4/15\n",
      "----------\n",
      "Loss is:1.57552145, Train Accuracy is:88.47%, Test Accuracy is:96.75%\n",
      "Epoch 5/15\n",
      "----------\n",
      "Loss is:1.48691598, Train Accuracy is:97.44%, Test Accuracy is:97.50%\n",
      "Epoch 6/15\n",
      "----------\n",
      "Loss is:1.48157750, Train Accuracy is:97.97%, Test Accuracy is:97.89%\n",
      "Epoch 7/15\n",
      "----------\n",
      "Loss is:1.47936844, Train Accuracy is:98.19%, Test Accuracy is:97.52%\n",
      "Epoch 8/15\n",
      "----------\n",
      "Loss is:1.47833712, Train Accuracy is:98.31%, Test Accuracy is:98.12%\n",
      "Epoch 9/15\n",
      "----------\n",
      "Loss is:1.47674243, Train Accuracy is:98.46%, Test Accuracy is:98.82%\n",
      "Epoch 10/15\n",
      "----------\n",
      "Loss is:1.47596690, Train Accuracy is:98.52%, Test Accuracy is:98.11%\n",
      "Epoch 11/15\n",
      "----------\n",
      "Loss is:1.47485858, Train Accuracy is:98.62%, Test Accuracy is:98.62%\n",
      "Epoch 12/15\n",
      "----------\n",
      "Loss is:1.47564501, Train Accuracy is:98.56%, Test Accuracy is:98.55%\n",
      "Epoch 13/15\n",
      "----------\n",
      "Loss is:1.47511709, Train Accuracy is:98.60%, Test Accuracy is:97.57%\n",
      "Epoch 14/15\n",
      "----------\n",
      "Loss is:1.47460060, Train Accuracy is:98.65%, Test Accuracy is:98.80%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for data in data_loader_train:\n",
    "        X_train, y_train = data\n",
    "        if use_cuda:\n",
    "            X_train, y_train = X_train.cuda(), y_train.cuda()\n",
    "        outputs = F.softmax(model(X_train))\n",
    "        _,pred = torch.max(outputs.data, 1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = cost(outputs, y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_correct += torch.sum(pred == y_train.data).item()\n",
    "    testing_correct = 0\n",
    "    for data in data_loader_test:\n",
    "        X_test, y_test = data\n",
    "        if use_cuda:\n",
    "            X_test, y_test = X_test.cuda(), y_test.cuda()\n",
    "        outputs = model(X_test)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        testing_correct += torch.sum(pred == y_test.data).item()\n",
    "    print(\"Loss is:{:.8f}, Train Accuracy is:{:.2f}%, Test Accuracy is:{:.2f}%\".format(running_loss*batch_size/len(data_train),\n",
    "                                                                                      100*running_correct/len(data_train),\n",
    "                                                                                      100*testing_correct/len(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the Explanations.\n",
    "1. wrap the model.\n",
    "2. create a classesLoader.\n",
    "3. set layers, model target and classes target.\n",
    "4. create Explainer, train the model and generate explanations.\n",
    "\n",
    "Here we choose [1,2,4,8] as target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\envs\\DL2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.decomposition.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "1it [00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training reducer:\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete, with size of (24393, 7, 7, 64)\n",
      "Training will take around a minute, please wait for a while...\n",
      "reducer trained, spent 38.787328004837036 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity: [0.22682747 0.18992594 0.03634965 0.08231129]\n",
      "loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  6.47it/s]\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimating weight:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:28<00:00,  1.88s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "loading training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.94it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate explanations with fullset condition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from Explainer import *\n",
    "import Explainer\n",
    "import utils \n",
    "import ClassesLoader \n",
    "import ModelWrapper \n",
    "\n",
    "\n",
    "m1 = ModelWrapper.PytorchModelWrapper(model,input_size = [1,28,28])\n",
    "\n",
    "classes = ClassesLoader.MNISTLoader(root = '/dataset')\n",
    "\n",
    "layers = [\"layer3\"]\n",
    "\n",
    "classesNos = [1,2,4,8]\n",
    "m1.target = (\"fc\",classesNos)\n",
    "classes.targetNos = classesNos\n",
    "n_components = 15\n",
    "\n",
    "for layer_name in layers:\n",
    "    \n",
    "    title = \"MNIST_\"+layer_name + \"_{}_{}\".format(n_components,classesNos)\n",
    "    try:\n",
    "        shutil.rmtree('Explainers/'+title)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    Exp = Explainer.Explainer(title = title,\n",
    "                    layer_name = layer_name,\n",
    "                    classesNos = classesNos,\n",
    "                    utils = utils.utils(img_size = (28,28,1)),\n",
    "                    #best_n = True,\n",
    "                    \n",
    "                    n_components= n_components\n",
    "\n",
    "                    #min_step=5\n",
    "                   )\n",
    "    \n",
    "    try:\n",
    "        Exp.train_model(m1,classes)\n",
    "    except:\n",
    "        Exp.reducer = None\n",
    "        Exp.train_model(m1,classes)\n",
    "    \n",
    "    Exp.generate_features(m1,classes)\n",
    "    \n",
    "    Exp.save_features()\n",
    "    \n",
    "    Exp.generate_image_LR_file(classes)\n",
    "    \n",
    "    Exp.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Explanations for 1,2,4,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/1.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/2.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/4.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/8.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"\".join([\"<table><tr>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/1.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/2.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/4.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/GE/8.jpg'></td>\",\n",
    "                      \"</tr></table>\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local explanations for a '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X,y),(tX,ty) = classes.load_all()\n",
    "x = tX[np.where(ty[:,1] == 1)][274]\n",
    "utils.utils(img_size = (28,28,1)).show_img([x])\n",
    "\n",
    "Exp.local_explanations(x,m1,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_1.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_2.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_4.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_8.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"\".join([\"<table><tr>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_1.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_2.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_4.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/0_8.jpg'></td>\",\n",
    "                      \"</tr></table>\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local explanation for a '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X,y),(tX,ty) = classes.load_all()\n",
    "x = tX[np.where(ty[:,2] == 1)][10]\n",
    "utils.utils(img_size = (28,28,1)).show_img([x])\n",
    "\n",
    "Exp.local_explanations(x,m1,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_1.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_2.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_4.jpg'></td><td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_8.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"\".join([\"<table><tr>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_1.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_2.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_4.jpg'></td>\",\n",
    "                      \"<td><img src='Explainers/MNIST_layer3_15_[1, 2, 4, 8]/explanations/all/1_8.jpg'></td>\",\n",
    "                      \"</tr></table>\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
