{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from torchsummary import summary\n",
    "import shutil\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple MNIST model, with only 6 layers. Global Average Pooling (GAP) and dense layers are used at last for consistent weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "            Conv2d-3           [-1, 16, 28, 28]           2,320\n",
      "              ReLU-4           [-1, 16, 28, 28]               0\n",
      "            Conv2d-5           [-1, 32, 14, 14]           4,640\n",
      "              ReLU-6           [-1, 32, 14, 14]               0\n",
      "            Conv2d-7           [-1, 32, 14, 14]           9,248\n",
      "              ReLU-8           [-1, 32, 14, 14]               0\n",
      "            Conv2d-9             [-1, 64, 7, 7]          18,496\n",
      "             ReLU-10             [-1, 64, 7, 7]               0\n",
      "           Conv2d-11             [-1, 64, 7, 7]          36,928\n",
      "             ReLU-12             [-1, 64, 7, 7]               0\n",
      "AdaptiveAvgPool2d-13             [-1, 64, 1, 1]               0\n",
      "           Linear-14                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 72,442\n",
      "Trainable params: 72,442\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.67\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 0.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "log_batch = 10\n",
    "unit_num = 16\n",
    "\n",
    "def _make_layer(in_shape, out_shape, unit_num):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_shape, unit_num, 3, 1, 1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(unit_num, out_shape, 3, 1, 1),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = _make_layer(1,unit_num,unit_num)\n",
    "        self.layer2 = _make_layer(unit_num,unit_num*2,unit_num*2)\n",
    "        self.layer3 = _make_layer(unit_num*2,unit_num*4,unit_num*4)\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(unit_num*4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = self.gap(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "model = Net()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset are stored in '/dataset'. If you want to change this, remember to change the root for ClassesLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "data_train = datasets.MNIST(root = \"./dataset\",\n",
    "                            transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = datasets.MNIST(root=\"./dataset\",\n",
    "                           transform = transform,\n",
    "                           train = False)\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True,\n",
    "                                                 num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True,\n",
    "                                                num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want a perfect MNIST classifier. Around 97% accuracy is enough for the explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(Path('model')):\n",
    "    os.mkdir(Path('model'))\n",
    "\n",
    "RETRAIN = False\n",
    "MODEL_PATH = Path('model/MNIST_model.pt') \n",
    "\n",
    "if not os.path.exists(MODEL_PATH) or RETRAIN:\n",
    "\n",
    "    cost = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    n_epochs = 10\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "        print(\"-\"*10)\n",
    "        for data in data_loader_train:\n",
    "            X_train, y_train = data\n",
    "            if use_cuda:\n",
    "                X_train, y_train = X_train.cuda(), y_train.cuda()\n",
    "            outputs = F.softmax(model(X_train))\n",
    "            _,pred = torch.max(outputs.data, 1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = cost(outputs, y_train)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_correct += torch.sum(pred == y_train.data).item()\n",
    "        testing_correct = 0\n",
    "        for data in data_loader_test:\n",
    "            X_test, y_test = data\n",
    "            if use_cuda:\n",
    "                X_test, y_test = X_test.cuda(), y_test.cuda()\n",
    "            outputs = model(X_test)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            testing_correct += torch.sum(pred == y_test.data).item()\n",
    "        print(\"Loss is:{:.8f}, Train Accuracy is:{:.2f}%, Test Accuracy is:{:.2f}%\".format(running_loss*batch_size/len(data_train),\n",
    "                                                                                          100*running_correct/len(data_train),\n",
    "                                                                                          100*testing_correct/len(data_test)))\n",
    "        \n",
    "    torch.save(model.state_dict(),MODEL_PATH)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    print ('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the Explanations.\n",
    "1. Create a loader list. Each loader only contains samples from one class.\n",
    "2. Wrap the model. Set all explanation related classes.\n",
    "3. create Explainer, train the model and generate explanations.\n",
    "\n",
    "Here we choose [1,2,4,8] as target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:MNIST_layer3_10_[3_8]\n",
      "target_classes:[3, 8]\n",
      "classes_names:['3', '8']\n",
      "n_components:10\n",
      "layer_name:layer3\n"
     ]
    }
   ],
   "source": [
    "import ICE.ModelWrapper\n",
    "import ICE.Explainer\n",
    "import ICE.utils\n",
    "import shutil\n",
    "\n",
    "\n",
    "target_classes = [3,8]\n",
    "classes_names = [str(i) for i in target_classes]\n",
    "layer_name = 'layer3'\n",
    "n_components = 10\n",
    "title = \"MNIST_{}_{}_[\".format(layer_name,n_components)+\"_\".join(classes_names) + ']'\n",
    "\n",
    "\n",
    "\n",
    "print (\"title:{}\".format(title))\n",
    "print (\"target_classes:{}\".format(target_classes))\n",
    "print (\"classes_names:{}\".format(classes_names))\n",
    "print (\"n_components:{}\".format(n_components))\n",
    "print (\"layer_name:{}\".format(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "wm = ICE.ModelWrapper.PytorchModelWrapper(model,batch_size=batch_size,predict_target=target_classes,input_size = [1,28,28],input_channel_first = True,model_channel_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data_train.data,data_train.targets\n",
    "loaders = []\n",
    "for target in target_classes:\n",
    "    tdataset = torch.utils.data.TensorDataset(X[y==target].unsqueeze(1))\n",
    "    loaders.append(torch.utils.data.DataLoader(tdataset,batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------\n",
      "Training reducer:\n",
      "1/5 Featuer maps gathered.\n",
      "loading complete, with size of (11982, 7, 7, 64)\n",
      "2/5 Reducer trained, spent 6.036442279815674 s.\n",
      "3/5 Error estimated, fidelity: [0.06354667 0.0652013 ].\n",
      "4/5 Weight estimator initialized.\n",
      "5/5 Weight estimated.\n",
      "visulizing features:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "loading training data\n",
      "Done with class: 3, 1/2\n",
      "Done with class: 8, 2/2\n",
      "Generate explanations with fullset condition\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"-------------------------------------------------------------------------------------------\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('Explainers/'+title)\n",
    "except:\n",
    "    pass\n",
    "# create an Explainer\n",
    "Exp = ICE.Explainer.Explainer(title = title,\n",
    "                layer_name = layer_name,\n",
    "                class_names = classes_names,\n",
    "                utils = ICE.utils.img_utils(img_size = (28,28),nchannels=1,img_format='channels_first'),\n",
    "                n_components = n_components,\n",
    "                reducer_type = \"NMF\"\n",
    "               )\n",
    "\n",
    "# train reducer based on target classes\n",
    "Exp.train_model(wm,loaders)\n",
    "# generate features \n",
    "Exp.generate_features(wm, loaders)\n",
    "# generate global explanations\n",
    "Exp.global_explanations()\n",
    "# save the explainer, use load() to load it with the same title\n",
    "Exp.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can load exist explainers with title\n",
    "Exp = ICE.Explainer.Explainer(title = title)\n",
    "Exp.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Explanations for 1,2,4,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='Explainers\\MNIST_layer3_10_[3_8]\\GE\\3.jpg'></td><td><img src='Explainers\\MNIST_layer3_10_[3_8]\\GE\\8.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import os\n",
    "fpath = os.path.join(\"Explainers\",title,\"GE\")\n",
    "paths = [os.path.join(fpath,fname) for fname in os.listdir(fpath)]\n",
    "display(HTML(\"\".join([\"<table><tr>\"]+[\"<td><img src='{}'></td>\".format(path) for path in paths]+[\"</tr></table>\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local explanations for a '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = data_test.data[data_test.targets==3][5]\n",
    "x = x.unsqueeze(0)\n",
    "Exp.utils.show_img([Exp.utils.deprocessing(x.permute(0,2,1).numpy())])\n",
    "x = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp.local_explanations(x,wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='Explainers\\MNIST_layer3_10_[3_8]\\explanations\\0\\explanation_0.jpg'></td><td><img src='Explainers\\MNIST_layer3_10_[3_8]\\explanations\\0\\explanation_1.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import os\n",
    "fpath = os.path.join(\"Explainers\",title,\"explanations\",\"0\")\n",
    "paths = [os.path.join(fpath,fname) for fname in os.listdir(fpath) if 'explanation' in fname]\n",
    "display(HTML(\"\".join([\"<table><tr>\"]+[\"<td><img src='{}'></td>\".format(path) for path in paths]+[\"</tr></table>\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
