{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will train some explainers based on pretrained models from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ICE.Data\n",
    "import ICE.ModelWrapper\n",
    "import ICE.Explainer\n",
    "import ICE.utils\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will train a husky explainer. It's based on ILSVRC2012 dataset, using class No.248.\n",
    "\n",
    "**We assume that you already have the ILSVRC2012 dataset.**\n",
    "\n",
    "This includes the following steps:\n",
    "1. Wrap the model with *get_feature*, *feature_predict*, and *predict* methods\n",
    "2. Provide a loader with data in form of (x,y)\n",
    "3. Train the Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ImageNet_path = '\\dataset\\ILSVRC2012'\n",
    "ImageNet_classes = []\n",
    "ImageNet_val = {i:[] for i in range(1000)}\n",
    "\n",
    "with open(os.path.join(ImageNet_path,'synset_words.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        tsplit = line.split('\\n')[0].split(' ')\n",
    "        path = os.path.join(ImageNet_path,'ILSVRC2012_img_train',tsplit[0])\n",
    "        name = ' '.join(tsplit[1:])\n",
    "        #print (path,name)\n",
    "        \n",
    "        ImageNet_classes.append((path,name))\n",
    "\n",
    "with open(os.path.join(ImageNet_path,'val.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        img,label = line.split('\\n')[0].split(' ')\n",
    "        \n",
    "        ImageNet_val[int(label)].append(os.path.join(ImageNet_path,'ILSVRC2012_img_val',img))\n",
    "\n",
    "def make_imgs(paths = [],labels = []):\n",
    "    imgs = []\n",
    "    for i,path in enumerate(paths):\n",
    "        imgs += [(os.path.join(path,t),labels[i]) for t in os.listdir(path)]\n",
    "    return imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:248_husky\n",
      "target_classes:[248]\n",
      "classes_names:['248 Eskimo dog, husky']\n",
      "n_components:10\n",
      "layer_name:layer4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_classes = [248]\n",
    "title = \"248_husky\"\n",
    "n_components = 10\n",
    "classes_names = [' '.join([str(idx),ImageNet_classes[idx][1]]) for idx in target_classes]\n",
    "layer_name = 'layer4'\n",
    "\n",
    "print (\"title:{}\".format(title))\n",
    "print (\"target_classes:{}\".format(target_classes))\n",
    "print (\"classes_names:{}\".format(classes_names))\n",
    "print (\"n_components:{}\".format(n_components))\n",
    "print (\"layer_name:{}\".format(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaders = [DataLoader(\n",
    "        ICE.Data.ImageDataset(make_imgs([ImageNet_classes[label][0]],[label]),\n",
    "                transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225]),\n",
    "                ])),\n",
    "        batch_size = 16,\n",
    "        num_workers=8,\n",
    "        #shuffle=True\n",
    ") for label in target_classes]\n",
    "\n",
    "\n",
    "m = models.resnet50(pretrained=True)\n",
    "m = m.cuda()\n",
    "m.eval()\n",
    "model = ICE.ModelWrapper.PytorchModelWrapper(m,batch_size=16,predict_target=target_classes,input_channel_first = False,model_channel_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------\n",
      "Training reducer:\n",
      "1/5 Featuer maps gathered.\n",
      "dataset too big, train with 0.77 instances\n",
      "loading complete, with size of (996, 7, 7, 2048)\n",
      "2/5 Reducer trained, spent 24.13231134414673 s.\n",
      "3/5 Error estimated, fidelity: [0.06015709].\n",
      "4/5 Weight estimator initialized.\n",
      "5/5 Weight estimated.\n",
      "visulizing features:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "loading training data\n",
      "Done with class: 248 Eskimo dog, husky, 1/1\n",
      "Generate explanations with fullset condition\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"-------------------------------------------------------------------------------------------\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('Explainers/'+title)\n",
    "except:\n",
    "    pass\n",
    "# create an Explainer\n",
    "Exp = ICE.Explainer.Explainer(title = title,\n",
    "                layer_name = layer_name,\n",
    "                class_names = classes_names,\n",
    "                utils = ICE.utils.img_utils(mode = \"torch\"),\n",
    "                n_components = n_components,\n",
    "                reducer_type = \"NMF\"\n",
    "               )\n",
    "\n",
    "# train reducer based on target classes\n",
    "Exp.train_model(model,loaders)\n",
    "# generate features \n",
    "Exp.generate_features(model, loaders)\n",
    "# generate global explanations\n",
    "Exp.global_explanations()\n",
    "# save the explainer, use load to load it with the same title\n",
    "Exp.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='Explainers\\248_husky\\GE\\248 Eskimo dog, husky.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import os\n",
    "fpath = os.path.join(\"Explainers\",title,\"GE\")\n",
    "paths = [os.path.join(fpath,fname) for fname in os.listdir(fpath)]\n",
    "display(HTML(\"\".join([\"<table><tr>\"]+[\"<td><img src='{}'></td>\".format(path) for path in paths]+[\"</tr></table>\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:dog_cat\n",
      "target_classes:[243, 282]\n",
      "classes_names:['243 bull mastiff', '282 tiger cat']\n",
      "n_components:10\n",
      "layer_name:layer4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_classes = [243,282]\n",
    "title = \"dog_cat\"\n",
    "n_components = 10\n",
    "classes_names = [' '.join([str(idx),ImageNet_classes[idx][1]]) for idx in target_classes]\n",
    "layer_name = 'layer4'\n",
    "\n",
    "print (\"title:{}\".format(title))\n",
    "print (\"target_classes:{}\".format(target_classes))\n",
    "print (\"classes_names:{}\".format(classes_names))\n",
    "print (\"n_components:{}\".format(n_components))\n",
    "print (\"layer_name:{}\".format(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaders = [DataLoader(\n",
    "        ICE.Data.ImageDataset(make_imgs([ImageNet_classes[label][0]],[label]),\n",
    "                transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225]),\n",
    "                ])),\n",
    "        batch_size = 16,\n",
    "        num_workers=8,\n",
    "        #shuffle=True\n",
    ") for label in target_classes]\n",
    "\n",
    "\n",
    "m = models.resnet50(pretrained=True)\n",
    "m = m.cuda()\n",
    "m.eval()\n",
    "model = ICE.ModelWrapper.PytorchModelWrapper(m,batch_size=16,predict_target=target_classes,input_channel_first = False,model_channel_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------\n",
      "Training reducer:\n",
      "1/5 Featuer maps gathered.\n",
      "dataset too big, train with 0.38 instances\n",
      "loading complete, with size of (996, 7, 7, 2048)\n",
      "2/5 Reducer trained, spent 20.493043184280396 s.\n",
      "3/5 Error estimated, fidelity: [0.05004624 0.0560113 ].\n",
      "4/5 Weight estimator initialized.\n",
      "5/5 Weight estimated.\n",
      "visulizing features:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "loading training data\n",
      "Done with class: 243 bull mastiff, 1/2\n",
      "Done with class: 282 tiger cat, 2/2\n",
      "Generate explanations with fullset condition\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"-------------------------------------------------------------------------------------------\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('Explainers/'+title)\n",
    "except:\n",
    "    pass\n",
    "# create an Explainer\n",
    "Exp = ICE.Explainer.Explainer(title = title,\n",
    "                layer_name = layer_name,\n",
    "                class_names = classes_names,\n",
    "                utils = ICE.utils.img_utils(mode = \"torch\"),\n",
    "                n_components = n_components,\n",
    "                reducer_type = \"NMF\"\n",
    "               )\n",
    "\n",
    "# train reducer based on target classes\n",
    "Exp.train_model(model,loaders)\n",
    "# generate features \n",
    "Exp.generate_features(model, loaders)\n",
    "# generate global explanations\n",
    "Exp.global_explanations()\n",
    "# save the explainer, use load to load it with the same title\n",
    "Exp.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate local explanation for catdog.png\n",
    "from PIL import Image\n",
    "img_path = \"catdog.png\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "x = transforms.ToTensor()(transforms.Resize(Exp.utils.fsize)(img))\n",
    "x = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(x).numpy()\n",
    "x = np.transpose(x,(1,2,0)) #to channel_last\n",
    "Exp.local_explanations(x,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='Explainers\\dog_cat\\explanations\\0\\explanation_0.jpg'></td><td><img src='Explainers\\dog_cat\\explanations\\0\\explanation_1.jpg'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import os\n",
    "fpath = os.path.join(\"Explainers\",title,\"explanations\",\"0\")\n",
    "paths = [os.path.join(fpath,fname) for fname in os.listdir(fpath) if 'explanation' in fname]\n",
    "display(HTML(\"\".join([\"<table><tr>\"]+[\"<td><img src='{}'></td>\".format(path) for path in paths]+[\"</tr></table>\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
